{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0aab011",
   "metadata": {},
   "source": [
    "# ADANNs for the Burgers PDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba13c0e",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "We consider the periodic burgers equation in 1d:\n",
    "$$\n",
    "    \\partial_t u (t, x)\n",
    "=\n",
    "    \\nu (\\partial_{x, x} u)(t, x) - \\frac{(\\partial_x u^2)(t, x)}{2}\n",
    "=\n",
    "    \\nu (\\partial_{x, x} u)(t, x) - (\\partial_x u)(t, x) u(t, x),\n",
    "$$\n",
    "for $(t, x) \\in [0,T] \\times [0, S]$ with periodic boundary conditions.\n",
    "\n",
    "We want to approximate the map\n",
    "$$\n",
    "\\Phi(u(0, \\cdot)) = u(T, \\cdot).\n",
    "$$\n",
    "\n",
    "Problem parameters:  $T, S, \\nu \\in (0,\\infty)$ and distribution of initial value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d66e86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:18:12.753661Z",
     "start_time": "2024-05-21T06:17:51.224490Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import torch\n",
    "import openpyxl\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sys.path.insert(1, '../1_Modules')\n",
    "\n",
    "# Importing the modules\n",
    "import random_function_generators\n",
    "import ode_methods\n",
    "import training\n",
    "import training_samples_generators\n",
    "import operator_learning_models\n",
    "import utils\n",
    "import burgers_classical_methods\n",
    "import evaluation_utils\n",
    "import documentation_utils\n",
    "import PDE_operations\n",
    "\n",
    "\n",
    "sys.path.insert(1, '1_ADANN_Modules')\n",
    "\n",
    "import ADANNs\n",
    "import ADANNs_training\n",
    "import ADANNs_grid\n",
    "import ADANNs_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564dbc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:18:12.774582Z",
     "start_time": "2024-05-21T06:18:12.757236Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reloading the modules\n",
    "importlib.reload(random_function_generators)\n",
    "importlib.reload(ode_methods)\n",
    "importlib.reload(training)\n",
    "importlib.reload(training_samples_generators)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(operator_learning_models)\n",
    "importlib.reload(burgers_classical_methods)\n",
    "importlib.reload(evaluation_utils)\n",
    "importlib.reload(documentation_utils)\n",
    "importlib.reload(PDE_operations)\n",
    "importlib.reload(ADANNs)\n",
    "importlib.reload(ADANNs_training)\n",
    "importlib.reload(ADANNs_grid)\n",
    "importlib.reload(ADANNs_opt)\n",
    "\n",
    "from random_function_generators import *\n",
    "from ode_methods import *\n",
    "from training import *\n",
    "from training_samples_generators import *\n",
    "from operator_learning_models import *\n",
    "from utils import *\n",
    "from burgers_classical_methods import *\n",
    "from evaluation_utils import *\n",
    "from documentation_utils import *\n",
    "from PDE_operations import *\n",
    "from ADANNs import *\n",
    "from ADANNs_training import *\n",
    "from ADANNs_grid import *\n",
    "from ADANNs_opt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b8be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:18:12.777963Z",
     "start_time": "2024-05-21T06:18:12.775901Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "test_run = False\n",
    "\n",
    "#Problem setup periodic Burgers PDE in 1d\n",
    "###################################################\n",
    "T = 1.\n",
    "space_size = 2 * np.pi\n",
    "laplace_factor = 0.1\n",
    "dim = 1 # Dimension can only be 1 for Burgers\n",
    "\n",
    "# initial value\n",
    "var = 1000\n",
    "decay_rate = 3.\n",
    "offset = np.power(var, 1/decay_rate)\n",
    "inner_decay = 2.\n",
    "initial_value_generator = RandnFourierSeriesGenerator([var, decay_rate, offset, inner_decay, space_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c119a2a3c7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:18:12.794512Z",
     "start_time": "2024-05-21T06:18:12.784190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Discretization operations\n",
    "x_values = x_values_periodic\n",
    "reduce_dimension = reduce_dimension_periodic\n",
    "get_higher_nr_spacediscr = get_higher_nr_spacediscr_periodic\n",
    "create_boundary_values = create_boundary_values_periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337546b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:18:12.809848Z",
     "start_time": "2024-05-21T06:18:12.794532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quantities derived from setup\n",
    "###################################################\n",
    "# Name of the PDE\n",
    "pde_name = f\"Burgers_T{T}_S{space_size}_nu{laplace_factor}_var{var}_decay{decay_rate}_offset{offset}_innerdecay{inner_decay}\"\n",
    "\n",
    "#Create folder for all outputs\n",
    "# output_folder_dir = create_output_folder(pde_name)\n",
    "output_folder_dir = \"Z Outputs/ADANNs (Server) - Full experiments/Z Outputs/ZZ 2024-04-18 13h38m41s Burgers_T1.0_S6.283185307179586_nu0.1_var1000_decay3.0_offset9.999999999999998_innerdecay2.0/\"\n",
    "\n",
    "#Prepare df to store data\n",
    "methods_data = pd.DataFrame(columns=[\"nr_params\", \"training_time\", \"test_time\", \"L2_error\", \"done_trainsteps\", \"learning_rate_history\", \"batch_size_history\"])\n",
    "methods = {}\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3666bd",
   "metadata": {},
   "source": [
    "### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea223bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:18:59.489253Z",
     "start_time": "2024-05-21T06:18:59.475565Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_data = True\n",
    "data_load_folder = \"2023-06-29 21h55m Code output/\"\n",
    "\n",
    "#Nr of input points allowed to be used by methods\n",
    "nr_spacediscr = 32\n",
    "\n",
    "#Method for reference solutions for training of models\n",
    "reference_algorithm = lambda initial_values, nr_timesteps: burgers_spectral_freqsp_lirk(initial_values, T, laplace_factor, space_size, nr_timesteps)\n",
    "\n",
    "# Train set parameters\n",
    "train_space_resolution_step = 2 if test_run else 4\n",
    "train_nr_timesteps = 20 if test_run else 1000\n",
    "nr_train_samples = 2**12 if test_run else 2**18\n",
    "nr_validation_samples = 2**10 if test_run else 2**14\n",
    "\n",
    "# Test set parameters\n",
    "test_space_resolution_step = 2 if test_run else 8\n",
    "test_nr_timesteps = 50 if test_run else 1500\n",
    "nr_test_samples = 2**10 if test_run else 2**14\n",
    "\n",
    "only_save_rough = True\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "parameters = {\n",
    "    'T': T,\n",
    "    'space_size': space_size,\n",
    "    'laplace_factor': laplace_factor,\n",
    "    'var': var,\n",
    "    'decay_rate': decay_rate,\n",
    "    'offset': offset,\n",
    "    'inner_decay': inner_decay,\n",
    "    'nr_spacediscr': nr_spacediscr,\n",
    "    'train_space_resolution_step': train_space_resolution_step,\n",
    "    'train_nr_timesteps': train_nr_timesteps,\n",
    "    'nr_train_samples': nr_train_samples,\n",
    "    'nr_validation_samples': nr_validation_samples,\n",
    "    'test_space_resolution_step': test_space_resolution_step,\n",
    "    'nr_test_samples': nr_test_samples,\n",
    "    'test_nr_timesteps': test_nr_timesteps,\n",
    "    'reference_algorithm': reference_algorithm.__name__,\n",
    "    'only_save_rough': only_save_rough\n",
    "}\n",
    "\n",
    "# save parametesr\n",
    "with open(output_folder_dir + 'train_test_parameters.json', 'w') as fp:\n",
    "    json.dump(parameters, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f546517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce train and test data\n",
    "train_nr_spacediscr = get_higher_nr_spacediscr(nr_spacediscr, train_space_resolution_step)\n",
    "test_nr_spacediscr = get_higher_nr_spacediscr(nr_spacediscr, test_space_resolution_step)\n",
    "\n",
    "print(\"Generating train samples\")\n",
    "train_initial_values_fine, train_ref_sol_fine, train_initial_values_rough, train_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_train_samples, train_nr_spacediscr, train_nr_timesteps, \n",
    "        reduce_dimension, train_space_resolution_step, 'train', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))\n",
    "training_samples_generator = TrainingSamplesGeneratorFromSolutions(train_initial_values_rough, train_ref_sol_rough)\n",
    "\n",
    "print(\"Generating validation samples\")\n",
    "validation_initial_values_fine, validation_ref_sol_fine, validation_initial_values_rough, validation_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_validation_samples, test_nr_spacediscr, test_nr_timesteps, \n",
    "        reduce_dimension, test_space_resolution_step, 'validate', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))\n",
    "\n",
    "print(\"Generating test samples\")\n",
    "test_initial_values_fine, test_ref_sol_fine, test_initial_values_rough, test_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_test_samples, test_nr_spacediscr, test_nr_timesteps, \n",
    "        reduce_dimension, test_space_resolution_step, 'test', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some reference solutions \n",
    "plot_reference_solutions(train_initial_values_rough, train_ref_sol_rough, 4, dim, x_values, space_size, pde_name, output_folder_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f018a",
   "metadata": {},
   "source": [
    "# Create models and methods to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358e1bc1812e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer_class = torch.optim.Adam\n",
    "# Loss function\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352040a5c1a82b1a",
   "metadata": {},
   "source": [
    "## Create and train ADANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8389b863dc758d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:19:11.374527Z",
     "start_time": "2024-05-21T06:19:11.360841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training hyperparams\n",
    "\n",
    "################\n",
    "# BASE\n",
    "base_training_kwargs = {\n",
    "    \"max_trainsteps\": 1 if test_run else 100000,\n",
    "    \"initial_batchsize\": 2**8 if test_run else 2**10,\n",
    "    \"max_batchsize\": 2**8 if test_run else 2**10,\n",
    "    \"output_steps\": 400 if test_run else 400,\n",
    "    \"eval_steps\": 400 if test_run else 400,\n",
    "    \"improvement_tolerance\": 0.96 if test_run else 0.96,\n",
    "    \"initial_lr\": None if test_run else None\n",
    "}\n",
    "\n",
    "# Learning rate parameters\n",
    "local_learning_rates = False if test_run else True\n",
    "base_lr_test_trainsteps = 1 if test_run else 50\n",
    "base_smallest_power = -10.\n",
    "base_largest_power = 2.\n",
    "base_maxiter = 1 if test_run else 15\n",
    "base_lr_search_parameters = [base_lr_test_trainsteps, base_smallest_power, base_largest_power, base_maxiter]\n",
    "\n",
    "\n",
    "################\n",
    "# DIFF\n",
    "only_train_base = False\n",
    "\n",
    "diff_training_kwargs = {\n",
    "    \"max_trainsteps\": 1 if test_run else 100000,\n",
    "    \"initial_batchsize\": base_training_kwargs[\"initial_batchsize\"],\n",
    "    \"max_batchsize\": base_training_kwargs[\"max_batchsize\"],\n",
    "    \"output_steps\": base_training_kwargs[\"output_steps\"],\n",
    "    \"eval_steps\": base_training_kwargs[\"eval_steps\"],\n",
    "    \"improvement_tolerance\": base_training_kwargs[\"improvement_tolerance\"],\n",
    "    \"initial_lr\": None if test_run else None\n",
    "}\n",
    "\n",
    "# Learning rate parameters\n",
    "diff_lr_test_trainsteps = 1 if test_run else 50\n",
    "diff_smallest_power = -10\n",
    "diff_largest_power = 0.\n",
    "diff_maxiter = 1 if test_run else 15\n",
    "diff_lr_search_parameters = [diff_lr_test_trainsteps, diff_smallest_power, diff_largest_power, diff_maxiter]\n",
    "\n",
    "# ADANNs Settings\n",
    "ADANN_base_model_class = SecondOrderLirkFDMPeriodicBurgersAdannBasemodel_learnFirstOrder\n",
    "base_model_kwargs = {\n",
    "    \"T\": T, \n",
    "    \"laplace_factor\": laplace_factor, \n",
    "    \"space_size\": space_size, \n",
    "    \"nr_spacediscr\": nr_spacediscr\n",
    "}\n",
    "\n",
    "# diff_model_class = FNOnDModel\n",
    "# diff_model_params = [16, 20, 4, 1]\n",
    "diff_model_class = ANNModel\n",
    "diff_model_params = [[nr_spacediscr, 2**8, 2**10, 2**8, nr_spacediscr]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda3264657af3de",
   "metadata": {},
   "source": [
    "#### ADANN Experiment 1: Grid based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0acca492cef8325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid\n",
    "grid_p1_low = 0.3 if test_run else 0.1\n",
    "grid_p1_high = 1.\n",
    "grid_nr_p1_steps = 1 if test_run else 4\n",
    "\n",
    "grid_p2_low = 0.3 if test_run else 0.1\n",
    "grid_p2_high = 1.\n",
    "grid_nr_p2_steps = 1 if test_run else 4\n",
    "\n",
    "param_grid_parameters = [grid_p1_low, grid_p1_high, grid_nr_p1_steps, grid_p2_low, grid_p2_high, grid_nr_p2_steps]\n",
    "\n",
    "list_base_nr_timesteps_grid = [4, 8, 16] if test_run else [4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad891c1db00c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adann_grid(\n",
    "    ADANN_base_model_class=ADANN_base_model_class,\n",
    "    base_model_kwargs=base_model_kwargs,\n",
    "    diff_model_class=diff_model_class,\n",
    "    diff_model_params=diff_model_params,\n",
    "    list_base_nr_timesteps=list_base_nr_timesteps_grid,\n",
    "    param_grid_parameters=param_grid_parameters,\n",
    "    training_samples_generator=training_samples_generator,\n",
    "    optimizer_class=optimizer_class,\n",
    "    loss_fn=loss_fn,\n",
    "    base_training_kwargs=base_training_kwargs,\n",
    "    base_lr_search_parameters=base_lr_search_parameters,\n",
    "    diff_training_kwargs=diff_training_kwargs,\n",
    "    diff_lr_search_parameters=diff_lr_search_parameters,\n",
    "    output_folder_dir=output_folder_dir,\n",
    "    methods=methods,\n",
    "    methods_data=methods_data,\n",
    "    test_input_values_rough=test_initial_values_rough,\n",
    "    test_ref_sol_rough=test_ref_sol_rough,\n",
    "    validation_input_values_rough=validation_initial_values_rough,\n",
    "    validation_ref_sol_rough=validation_ref_sol_rough,\n",
    "    pde_name=pde_name,\n",
    "    space_size=space_size,\n",
    "    dim=dim,\n",
    "    only_train_base=only_train_base,\n",
    "    local_learning_rates=local_learning_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2835b7106dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_heat_maps_combined(output_folder_dir, only_train_base, list_base_nr_timesteps_grid, pde_name=pde_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d0df4d13ab9b4",
   "metadata": {},
   "source": [
    "#### ADANN Experiment 2: Optimization based approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db88c403aed47995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1_low = 0.1 if test_run else grid_p1_low\n",
    "# p1_high = 0.9 if test_run else grid_p1_high\n",
    "# p2_low = 0.2 if test_run else grid_p2_low\n",
    "# p2_high = 0.9 if test_run else grid_p2_high\n",
    "# n_calls = 25 if test_run else 25\n",
    "# \n",
    "# p1_low_start = p1_low\n",
    "# p1_high_start = p1_high\n",
    "# p2_low_start = p2_low\n",
    "# p2_high_start = p2_high\n",
    "# n_random_starts = 16 if test_run else 16\n",
    "# \n",
    "# opt_params = [p1_low, p1_high, p2_low, p2_high, n_calls, p1_low_start, p1_high_start, p2_low_start, p2_high_start, n_random_starts]\n",
    "# \n",
    "# list_base_nr_timesteps_opt = [4, 8, 16] if test_run else [4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11e894784ec3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adann_opt(\n",
    "#     ADANN_base_model_class=ADANN_base_model_class,\n",
    "#     base_model_kwargs=base_model_kwargs,\n",
    "#     diff_model_class=diff_model_class,\n",
    "#     diff_model_params=diff_model_params,\n",
    "#     list_base_nr_timesteps=list_base_nr_timesteps_opt,\n",
    "#     opt_params=opt_params,\n",
    "#     training_samples_generator=training_samples_generator,\n",
    "#     optimizer_class=optimizer_class,\n",
    "#     loss_fn=loss_fn,\n",
    "#     base_training_kwargs=base_training_kwargs,\n",
    "#     base_lr_search_parameters=base_lr_search_parameters,\n",
    "#     diff_training_kwargs=diff_training_kwargs,\n",
    "#     diff_lr_search_parameters=diff_lr_search_parameters,\n",
    "#     output_folder_dir=output_folder_dir,\n",
    "#     methods=methods,\n",
    "#     methods_data=methods_data,\n",
    "#     test_input_values_rough=test_initial_values_rough,\n",
    "#     test_ref_sol_rough=test_ref_sol_rough,\n",
    "#     validation_input_values_rough=validation_initial_values_rough,\n",
    "#     validation_ref_sol_rough=validation_ref_sol_rough,\n",
    "#     pde_name=pde_name,\n",
    "#     space_size=space_size,\n",
    "#     dim=dim,\n",
    "#     only_train_base=only_train_base,\n",
    "#     local_learning_rates=local_learning_rates\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b4a08ec6b705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_opt_results_combined(output_folder_dir, pde_name=pde_name, list_base_nr_timesteps=list_base_nr_timesteps_opt, only_train_base=only_train_base, n_random_starts=opt_params[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5729072",
   "metadata": {},
   "source": [
    "### Standard operator learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparams\n",
    "OL_training_kwargs = {\n",
    "    \"max_trainsteps\": 1 if test_run else 100000,\n",
    "    \"initial_batchsize\": base_training_kwargs[\"initial_batchsize\"],\n",
    "    \"max_batchsize\": base_training_kwargs[\"initial_batchsize\"],\n",
    "    \"output_steps\": 20 if test_run else 200,\n",
    "    \"eval_steps\": 10 if test_run else diff_training_kwargs[\"eval_steps\"],\n",
    "    \"improvement_tolerance\": 0.8 if test_run else diff_training_kwargs[\"improvement_tolerance\"],\n",
    "    \"initial_lr\": None if test_run else None\n",
    "}\n",
    "nr_runs = 1 if test_run else grid_nr_p1_steps * grid_nr_p2_steps\n",
    "\n",
    "# learning rates\n",
    "local_learning_rates=False\n",
    "lr_test_trainsteps = 20 if test_run else 100\n",
    "smallest_power = -10\n",
    "largest_power = 0.\n",
    "maxiter = 1 if test_run else 15\n",
    "OL_lr_search_parameters = [lr_test_trainsteps, smallest_power, largest_power, maxiter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0710da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN models\n",
    "ann_foldername = output_folder_dir + \"Results_ANN\"\n",
    "\n",
    "#ANN Parameters [layer_dims]\n",
    "list_ann_params = [\n",
    "    [[nr_spacediscr, 2**7, 2**9, 2**7, nr_spacediscr]],\n",
    "    [[nr_spacediscr, 2**8, 2**10, 2**8, nr_spacediscr]],\n",
    "    [[nr_spacediscr, 2**8, 2**10, 2**12, 2**10, 2**8, nr_spacediscr]]\n",
    "]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = ANNModel, \n",
    "    list_params = list_ann_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=OL_lr_search_parameters,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = ann_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=local_learning_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNO models\n",
    "fno_foldername = output_folder_dir + \"Results_FNO\"\n",
    "\n",
    "#list is [#modes, width, depth, dim]\n",
    "list_fno_params = [\n",
    "    [8, 20, 3, 1],\n",
    "    [16, 30, 4, 1],\n",
    "    [32, 40, 5, 1]\n",
    "]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = FNOnDModel, \n",
    "    list_params = list_fno_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=OL_lr_search_parameters,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = fno_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=local_learning_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977d2b5",
   "metadata": {},
   "source": [
    "### Classical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b49bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization parameters\n",
    "nr_timesteps_fdm = list_base_nr_timesteps_grid\n",
    "\n",
    "#Create all methods for the correponding timesteps\n",
    "# FDM (I do not evaluate the euler method at the moment)\n",
    "for nr_timesteps in nr_timesteps_fdm:\n",
    "    for v in [2]: \n",
    "        name = f\"FDM ({nr_timesteps} Crank-Nicolson time steps)\"\n",
    "        methods[name] = SecondOrderLirkFDMPeriodicBurgersAdannBasemodel_learnFirstOrder(T, laplace_factor, space_size, nr_spacediscr, nr_timesteps, v).to(device)\n",
    "        methods_data.at[name, \"training_time\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa10166-12d2-47ba-a4e6-40a49a8d4d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nr_timesteps in nr_timesteps_fdm:\n",
    "#     for implicit_first in [False, True]:\n",
    "#         name = f\"Lax-Wendroff FDM ({nr_timesteps} Strang splitting steps with {implicit_first})\"\n",
    "#         methods[name] = lambda initial_values, nr_timesteps=nr_timesteps: burger_fdm_strang_splitting_lax_wendroff(initial_values, T, laplace_factor, space_size, nr_timesteps, implicit_first)\n",
    "#         methods_data.at[name, \"training_time\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b165bfb",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443354c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the methods and create plots\n",
    "nr_of_eval_runs = 1 if test_run else 1000\n",
    "plot_histogram = False if test_run else True\n",
    "\n",
    "method_categories = ([\"ANN\", \"FNO\", \"FDM\"] + \n",
    "                     ([\"ADANN base - grid\"] if only_train_base else [\"ADANN base - grid\", \"ADANN full - grid\"]) +\n",
    "                     ([\"ADANN base - EE\"] if only_train_base else [\"ADANN full - EE\"])\n",
    "                     )\n",
    "space_grid = x_values(nr_spacediscr, space_size)\n",
    "\n",
    "evaluate_and_plot(methods, \n",
    "                  methods_data, \n",
    "                  method_categories, \n",
    "                  test_initial_values_rough, \n",
    "                  test_ref_sol_rough, \n",
    "                  space_grid, \n",
    "                  space_size, \n",
    "                  output_folder_dir, \n",
    "                  pde_name, \n",
    "                  dim=dim, \n",
    "                  nr_of_eval_runs=nr_of_eval_runs, \n",
    "                  plot_histogram=plot_histogram,\n",
    "                  legend_loc=None,\n",
    "                  nr_of_plots=1 if test_run else 3\n",
    "                  )\n",
    "\n",
    "#Save all the data in an Excel sheet\n",
    "local_vars = locals()\n",
    "params_dict = {k: [v] for k, v in local_vars.items() if isinstance(v, (int, str, float)) and k[0] != '_'}\n",
    "save_excel_sheet(methods_data, params_dict, output_folder_dir + f\"Results_{pde_name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843c3367ad940a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:19:18.201010Z",
     "start_time": "2024-05-21T06:19:15.602361Z"
    }
   },
   "outputs": [],
   "source": [
    "create_error_vs_comptime_plot(method_categories, output_folder_dir, pde_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_PDE_survey",
   "language": "python",
   "name": "venv_pde_survey"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
