{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADANNs for the semilinear PDEs\n",
    "Adjusted from ADANN_SG.ipynb from first version of ADANN project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "We consider the semilinear heat PDE d dimensions:\n",
    "$$\n",
    "    \\partial_t u (t, x)\n",
    "=\n",
    "    \\nu (\\Delta_{x} u)(t, x) + f(u(t, x)),\n",
    "$$\n",
    "for $(t, x) \\in [0,T] \\times [0, S]^d$ with perdiodic boundary conditions.\n",
    "\n",
    "We want to approximate the map\n",
    "$$\n",
    "\\Phi(u(0, \\cdot)) = u(T, \\cdot).\n",
    "$$\n",
    "\n",
    "Problem parameters:  $T, S, \\nu \\in (0,\\infty)$, $f \\colon \\mathbb{R} \\to \\mathbb{R}$, and distribution of initial value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:23:02.970865Z",
     "start_time": "2024-05-21T06:22:58.762092Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import importlib\n",
    "import time \n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sys.path.insert(1, '../1_Modules')\n",
    "\n",
    "# Importing the modules\n",
    "import random_function_generators\n",
    "import ode_methods\n",
    "import training\n",
    "import training_samples_generators\n",
    "import operator_learning_models\n",
    "import utils\n",
    "import semilinear_heat_multi_d_classical_methods\n",
    "import evaluation_utils\n",
    "import documentation_utils\n",
    "import PDE_operations\n",
    "\n",
    "sys.path.insert(1, '1_ADANN_Modules')\n",
    "\n",
    "import ADANNs\n",
    "import ADANNs_training\n",
    "import ADANNs_grid\n",
    "import ADANNs_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:23:03.005645Z",
     "start_time": "2024-05-21T06:23:02.979815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reloading the modules\n",
    "importlib.reload(random_function_generators)\n",
    "importlib.reload(ode_methods)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(training)\n",
    "importlib.reload(training_samples_generators)\n",
    "importlib.reload(operator_learning_models)\n",
    "importlib.reload(semilinear_heat_multi_d_classical_methods)\n",
    "importlib.reload(evaluation_utils)\n",
    "importlib.reload(documentation_utils)\n",
    "importlib.reload(PDE_operations)\n",
    "importlib.reload(ADANNs)\n",
    "importlib.reload(ADANNs_training)\n",
    "importlib.reload(ADANNs_grid)\n",
    "importlib.reload(ADANNs_opt)\n",
    "\n",
    "\n",
    "from random_function_generators import *\n",
    "from ode_methods import *\n",
    "from training import *\n",
    "from training_samples_generators import *\n",
    "from operator_learning_models import *\n",
    "from utils import *\n",
    "from semilinear_heat_multi_d_classical_methods import *\n",
    "from evaluation_utils import *\n",
    "from documentation_utils import *\n",
    "from PDE_operations import *\n",
    "from ADANNs import *\n",
    "from ADANNs_training import *\n",
    "from ADANNs_grid import *\n",
    "from ADANNs_opt import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:24:00.790429Z",
     "start_time": "2024-05-21T06:24:00.665696Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "test_run = True\n",
    "\n",
    "# Problem setup for periodic semilinear PDE\n",
    "###################################################\n",
    "T = 2.\n",
    "space_size = 1.\n",
    "laplace_factor = 0.01\n",
    "dim = 1\n",
    "nonlin = lambda x : torch.sin(np.pi * x)\n",
    "nonlin_name = \"Sine\"\n",
    "# nonlin = lambda x : (1-x) / (1 + x**2)\n",
    "# nonlin_name = \"Fraction\"\n",
    "\n",
    "# initial value\n",
    "var = 10**5\n",
    "decay_rate = 2\n",
    "offset = np.power(var, 1/decay_rate)\n",
    "inner_decay = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:24:05.631894Z",
     "start_time": "2024-05-21T06:24:05.524440Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_value_generator = RandnFourierSeriesGenerator([var, decay_rate, offset, inner_decay, space_size, dim])\n",
    "#Discretization operations\n",
    "x_values = x_values_periodic\n",
    "reduce_dimension = lambda values, space_resolution_step: reduce_dimension_periodic(values, space_resolution_step, dim=dim)\n",
    "get_higher_nr_spacediscr = get_higher_nr_spacediscr_periodic\n",
    "create_boundary_values = create_boundary_values_periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:24:09.861571Z",
     "start_time": "2024-05-21T06:24:09.839958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Name of the problem\n",
    "pde_name = f\"Semilinear_heat_{dim}-dimensional_T_{T}_space_size_{space_size}_laplace_factor_{laplace_factor}_nonlin_{nonlin_name}_var_{var}_decay_rate_{decay_rate}_offset_{offset}_inner_decay_{inner_decay}\"\n",
    "\n",
    "#Create folder for all outputs\n",
    "# output_folder_dir = create_output_folder(pde_name)\n",
    "# output_folder_dir = \"Z Outputs/ADANNs (Server) - Full experiments/Z Outputs/ZZ 2024-04-18 07h53m07s Semilinear_heat_1-dimensional_T_2.0_space_size_1.0_laplace_factor_0.01_nonlin_Sine_var_100000_decay_rate_2_offset_316.22776601683796_inner_decay_1.0/\"\n",
    "output_folder_dir = \"Z Outputs/ADANNs (Server) - Full experiments/Z Outputs/ZZ 2024-04-19 05h32m34s Semilinear_heat_2-dimensional_T_2.0_space_size_1.0_laplace_factor_0.01_nonlin_Sine_var_100000_decay_rate_2_offset_316.22776601683796_inner_decay_1.0/\"\n",
    "\n",
    "# Prepare df to store data\n",
    "methods_data = pd.DataFrame(columns=[\"nr_params\", \"training_time\", \"test_time\", \"L2_error\", \"done_trainsteps\", \"learning_rate_history\", \"batch_size_history\"])\n",
    "methods = {}\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:24:11.178977Z",
     "start_time": "2024-05-21T06:24:11.155471Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_data = True \n",
    "data_load_folder = f\"Z Outputs/ZZ 2023-11-21 08h55m16s {pde_name}/\"\n",
    "\n",
    "#Nr of input points allowed to be used by methods\n",
    "nr_spacediscr = 16 if test_run else (64 if dim==1 else 32)\n",
    "\n",
    "#Method for reference solutions for training of models\n",
    "reference_algorithm = lambda initial_values, nr_timesteps: periodic_semilinear_pde_spectral_lirk(initial_values, T, laplace_factor, nonlin, space_size, nr_timesteps, dim=dim)\n",
    "\n",
    "# Train set parameters\n",
    "train_space_resolution_step = 2 if test_run else (4 if dim==1 else 2)\n",
    "train_nr_timesteps = 20 if test_run else 1000\n",
    "nr_train_samples = 2**10 if test_run else (2**18 if dim==1 else 2**16)\n",
    "nr_validation_samples = 2**10 if test_run else (2**14 if dim==1 else 2**11)\n",
    "\n",
    "test_space_resolution_step = 2 if test_run else (8 if dim==1 else 4)\n",
    "test_nr_timesteps = 50 if test_run else 1500\n",
    "nr_test_samples = 2**10 if test_run else (2**14 if dim==1 else 2**11)\n",
    "\n",
    "only_save_rough = True\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "parameters = {\n",
    "    'T': T,\n",
    "    'space_size': space_size,\n",
    "    'laplace_factor': laplace_factor,\n",
    "    'var': var,\n",
    "    'dim': dim,\n",
    "    'decay_rate': decay_rate,\n",
    "    'offset': offset,\n",
    "    'inner_decay': inner_decay,\n",
    "    'nr_spacediscr': nr_spacediscr,\n",
    "    'train_space_resolution_step': train_space_resolution_step,\n",
    "    'train_nr_timesteps': train_nr_timesteps,\n",
    "    'nr_train_samples': nr_train_samples,\n",
    "    'nr_validation_samples': nr_validation_samples,\n",
    "    'test_space_resolution_step': test_space_resolution_step,\n",
    "    'nr_test_samples': nr_test_samples,\n",
    "    'test_nr_timesteps': test_nr_timesteps,\n",
    "    'reference_algorithm': reference_algorithm.__name__,\n",
    "    'only_save_rough': only_save_rough\n",
    "}\n",
    "\n",
    "# save parametesr\n",
    "with open(output_folder_dir + 'train_test_parameters.json', 'w') as fp:\n",
    "    json.dump(parameters, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce train and test data\n",
    "train_nr_spacediscr = get_higher_nr_spacediscr(nr_spacediscr, train_space_resolution_step)\n",
    "test_nr_spacediscr = get_higher_nr_spacediscr(nr_spacediscr, test_space_resolution_step)\n",
    "\n",
    "print(\"Generating train samples\")\n",
    "train_initial_values_fine, train_ref_sol_fine, train_initial_values_rough, train_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_train_samples, train_nr_spacediscr, train_nr_timesteps, \n",
    "        reduce_dimension, train_space_resolution_step, 'train', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))\n",
    "training_samples_generator = TrainingSamplesGeneratorFromSolutions(train_initial_values_rough, train_ref_sol_rough)\n",
    "\n",
    "print(\"Generating validation samples\")\n",
    "validation_initial_values_fine, validation_ref_sol_fine, validation_initial_values_rough, validation_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_validation_samples, test_nr_spacediscr, test_nr_timesteps, \n",
    "        reduce_dimension, test_space_resolution_step, 'validate', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))\n",
    "\n",
    "print(\"Generating test samples\")\n",
    "test_initial_values_fine, test_ref_sol_fine, test_initial_values_rough, test_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_test_samples, test_nr_spacediscr, test_nr_timesteps, \n",
    "        reduce_dimension, test_space_resolution_step, 'test', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some reference solutions\n",
    "plot_reference_solutions(train_initial_values_rough, train_ref_sol_rough, 3, dim, x_values, space_size, pde_name, output_folder_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models and methods to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer_class = torch.optim.Adam\n",
    "# Loss function\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train ADANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:24:14.624883Z",
     "start_time": "2024-05-21T06:24:14.597115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training hyperparams\n",
    "\n",
    "################\n",
    "# BASE\n",
    "base_training_kwargs = {\n",
    "    \"max_trainsteps\": 1 if test_run else 100000,\n",
    "    \"initial_batchsize\": 2**8 if dim==1 else 2**7,\n",
    "    \"max_batchsize\": 2**8 if dim==1 else 2**7,\n",
    "    \"output_steps\": 400 if test_run else 400,\n",
    "    \"eval_steps\": 400 if test_run else 400,\n",
    "    \"improvement_tolerance\": 0.96 if test_run else 0.96,\n",
    "    \"initial_lr\": None if test_run else None\n",
    "}\n",
    "\n",
    "# Learning rate parameters\n",
    "local_learning_rates = True\n",
    "base_lr_test_trainsteps = 1 if test_run else 50\n",
    "base_smallest_power = -20\n",
    "base_largest_power = 5.\n",
    "base_maxiter = 1 if test_run else 15\n",
    "base_lr_search_parameters = [base_lr_test_trainsteps, base_smallest_power, base_largest_power, base_maxiter]\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "# DIFF\n",
    "only_train_base = True\n",
    "\n",
    "diff_training_kwargs = {\n",
    "    \"max_trainsteps\": 0 if test_run else 100000,\n",
    "    \"initial_batchsize\": base_training_kwargs[\"initial_batchsize\"],\n",
    "    \"max_batchsize\": base_training_kwargs[\"initial_batchsize\"],\n",
    "    \"output_steps\": 100 if test_run else 200,\n",
    "    \"eval_steps\": 100 if test_run else 100,\n",
    "    \"improvement_tolerance\": 0.96 if test_run else 0.96,\n",
    "    \"initial_lr\": None if test_run else 0.001\n",
    "}\n",
    "\n",
    "# Learning rate parameters\n",
    "diff_lr_test_trainsteps = 1 if test_run else 100\n",
    "diff_smallest_power = -10\n",
    "diff_largest_power = 0.\n",
    "diff_maxiter = 1 if test_run else 15\n",
    "diff_lr_search_parameters = [diff_lr_test_trainsteps, diff_smallest_power, diff_largest_power, diff_maxiter]\n",
    "\n",
    "\n",
    "# ADANNs Settings\n",
    "ADANN_base_model_class = SecondOrderLirkFDMPeriodicSemilinearPDEAdannBasemodel\n",
    "base_model_kwargs = {\"T\": T, \n",
    "                     \"laplace_factor\": laplace_factor, \n",
    "                     \"nonlin\": nonlin, \n",
    "                     \"space_size\": space_size, \n",
    "                     \"nr_spacediscr\": nr_spacediscr, \n",
    "                     \"nonlin_name\": nonlin_name, \n",
    "                     \"dim\": dim\n",
    "                     }\n",
    "\n",
    "diff_model_class = ANNModel \n",
    "diff_model_params = [[nr_spacediscr, 200, 500, 500, 200, nr_spacediscr]] if dim==1 else [[nr_spacediscr**dim, 2**11, 2**12, 2**11, nr_spacediscr**dim]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADANN Experiment 1: Grid based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid\n",
    "grid_p1_low = 0.1\n",
    "grid_p1_high = 1.2\n",
    "grid_nr_p1_steps = 2 if test_run else (5 if dim==1 else 5)\n",
    "\n",
    "grid_p2_low = 0.2 if test_run else (0.25 if dim==1 else 0.1)\n",
    "grid_p2_high = 1.2\n",
    "grid_nr_p2_steps = 2 if test_run else (5 if dim==1 else 5)\n",
    "\n",
    "param_grid_parameters = [grid_p1_low, grid_p1_high, grid_nr_p1_steps, grid_p2_low, grid_p2_high, grid_nr_p2_steps]\n",
    "\n",
    "list_base_nr_timesteps_grid = [2, 4, 8] if test_run else ([2, 4, 8] if dim ==1 else [2, 4, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim==1:\n",
    "    adann_grid(\n",
    "        ADANN_base_model_class=ADANN_base_model_class,\n",
    "        base_model_kwargs=base_model_kwargs,\n",
    "        diff_model_class=diff_model_class,\n",
    "        diff_model_params=diff_model_params,\n",
    "        list_base_nr_timesteps=list_base_nr_timesteps_grid,\n",
    "        param_grid_parameters=param_grid_parameters,\n",
    "        training_samples_generator=training_samples_generator,\n",
    "        optimizer_class=optimizer_class,\n",
    "        loss_fn=loss_fn,\n",
    "        base_training_kwargs=base_training_kwargs,\n",
    "        base_lr_search_parameters=base_lr_search_parameters,\n",
    "        diff_training_kwargs=diff_training_kwargs,\n",
    "        diff_lr_search_parameters=diff_lr_search_parameters,\n",
    "        output_folder_dir=output_folder_dir,\n",
    "        methods=methods,\n",
    "        methods_data=methods_data,\n",
    "        test_input_values_rough=test_initial_values_rough,\n",
    "        test_ref_sol_rough=test_ref_sol_rough,\n",
    "        validation_input_values_rough=validation_initial_values_rough,\n",
    "        validation_ref_sol_rough=validation_ref_sol_rough,\n",
    "        pde_name=pde_name,\n",
    "        space_size=space_size,\n",
    "        dim=dim,\n",
    "        only_train_base=only_train_base,\n",
    "        local_learning_rates=local_learning_rates\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim==1:\n",
    "    plot_error_heat_maps_combined(output_folder_dir, only_train_base, list_base_nr_timesteps_grid, pde_name=pde_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADANN Experiment 2: Heuristic approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_low = 0.1 if test_run else 0.1\n",
    "p1_high = 1.2 if test_run else 1.2\n",
    "p2_low = 0.25 if test_run else 0.25\n",
    "p2_high = 1.2 if test_run else 1.2\n",
    "n_calls = 4 if test_run else 12\n",
    "\n",
    "p1_low_start = p1_low\n",
    "p1_high_start = p1_high \n",
    "p2_low_start = p2_low \n",
    "p2_high_start = p2_high \n",
    "n_random_starts = 2 if test_run else 8\n",
    "\n",
    "opt_params = [p1_low, p1_high, p2_low, p2_high, n_calls, p1_low_start, p1_high_start, p2_low_start, p2_high_start, n_random_starts]\n",
    "\n",
    "list_base_nr_timesteps_opt = [2, 4, 8] if test_run else ([2, 4, 8] if dim ==1 else [2, 4, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adann_opt(\n",
    "    ADANN_base_model_class=ADANN_base_model_class,\n",
    "    base_model_kwargs=base_model_kwargs,\n",
    "    diff_model_class=diff_model_class,\n",
    "    diff_model_params=diff_model_params,\n",
    "    list_base_nr_timesteps=list_base_nr_timesteps_opt,\n",
    "    opt_params=opt_params,\n",
    "    training_samples_generator=training_samples_generator,\n",
    "    optimizer_class=optimizer_class,\n",
    "    loss_fn=loss_fn,\n",
    "    base_training_kwargs=base_training_kwargs,\n",
    "    base_lr_search_parameters=base_lr_search_parameters,\n",
    "    diff_training_kwargs=diff_training_kwargs,\n",
    "    diff_lr_search_parameters=diff_lr_search_parameters,\n",
    "    output_folder_dir=output_folder_dir,\n",
    "    methods=methods,\n",
    "    methods_data=methods_data,\n",
    "    test_input_values_rough=test_initial_values_rough,\n",
    "    test_ref_sol_rough=test_ref_sol_rough,\n",
    "    validation_input_values_rough=validation_initial_values_rough,\n",
    "    validation_ref_sol_rough=validation_ref_sol_rough,\n",
    "    pde_name=pde_name,\n",
    "    space_size=space_size,\n",
    "    dim=dim,\n",
    "    only_train_base=only_train_base,\n",
    "    local_learning_rates=local_learning_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_opt_results_combined(output_folder_dir, pde_name=pde_name, list_base_nr_timesteps=list_base_nr_timesteps_opt, only_train_base=only_train_base, n_random_starts=opt_params[-1], cutoff=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard operator learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall training parameters\n",
    "OL_training_kwargs = {\n",
    "    \"max_trainsteps\": 1 if test_run else 100000,\n",
    "    \"initial_batchsize\": base_training_kwargs[\"initial_batchsize\"],\n",
    "    \"max_batchsize\": base_training_kwargs[\"initial_batchsize\"],\n",
    "    \"output_steps\": 20 if test_run else base_training_kwargs[\"output_steps\"],\n",
    "    \"eval_steps\": 10 if test_run else base_training_kwargs[\"eval_steps\"],\n",
    "    \"improvement_tolerance\": 0.8 if test_run else base_training_kwargs[\"improvement_tolerance\"],\n",
    "    \"initial_lr\": None if test_run else None\n",
    "}\n",
    "nr_runs = 1 if test_run else n_calls\n",
    "\n",
    "# learning rates\n",
    "local_learning_rates=True\n",
    "lr_test_trainsteps = 1 if test_run else base_lr_test_trainsteps\n",
    "smallest_power = -20\n",
    "largest_power = 5.\n",
    "maxiter = 1 if test_run else 15\n",
    "OL_lr_search_parameters = [lr_test_trainsteps, smallest_power, largest_power, maxiter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN models\n",
    "ann_foldername = output_folder_dir + \"Results_ANN\"\n",
    "\n",
    "input_dim = nr_spacediscr**dim\n",
    "\n",
    "#ANN Parameters\n",
    "list_ann_params = [\n",
    "    [[input_dim, 2**9, 2**9, input_dim]] if dim==1 else [[input_dim, 2**11, 2**11, input_dim]],\n",
    "    [[input_dim, 2**9, 2**11, 2**9, input_dim]] if dim==1 else [[input_dim, 2**11, 2**12, 2**11, input_dim]],\n",
    "    [[input_dim, 2**9, 2**11, 2**13, 2**11, 2**9,  input_dim]] if dim==1 else [[input_dim, 2**11, 2**12, 2**13, 2**12, 2**11, input_dim]]\n",
    "]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = ANNModel, \n",
    "    list_params = list_ann_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=OL_lr_search_parameters,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = ann_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=local_learning_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNO models\n",
    "fno_foldername = output_folder_dir + \"Results_FNO\"\n",
    "\n",
    "#list is [#modes, width, depth, dim]\n",
    "list_fno_params = [\n",
    "    [8, 20, 3, dim],\n",
    "    [16, 30, 4, dim],\n",
    "    [16 if test_run else 32, 40, 5, dim]\n",
    "]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = FNOnDModel, \n",
    "    list_params = list_fno_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=OL_lr_search_parameters,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = fno_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=local_learning_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Discretization parameters\n",
    "nr_timesteps_fdm = list_base_nr_timesteps_opt\n",
    "\n",
    "#Create all methods for the correponding timesteps\n",
    "for nr_timesteps in nr_timesteps_fdm:\n",
    "    name = f\"FDM ({nr_timesteps} Crank-Nicolson time steps)\"\n",
    "    methods[name] = SecondOrderLirkFDMPeriodicSemilinearPDEAdannBasemodel(T, laplace_factor, nonlin, space_size, nr_spacediscr, nr_timesteps, nonlin_name=nonlin_name, dim=dim, scale=True).to(device)\n",
    "    methods_data.at[name, \"training_time\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:23:30.922508Z",
     "start_time": "2024-05-21T06:23:30.757307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate all the methods and create plots\n",
    "nr_of_eval_runs = 2 if test_run else 1000\n",
    "plot_histogram = False if test_run else True\n",
    "\n",
    "method_categories = ([\"ANN\", \"FNO\", \"FDM\"] +\n",
    "                     ([\"ADANN base - grid\"] if only_train_base else [\"ADANN base - grid\", \"ADANN full - grid\"]) +\n",
    "                     ([\"ADANN base - EE\"] if only_train_base else [\"ADANN full - EE\"])\n",
    "                     )\n",
    "\n",
    "space_grid = x_values(nr_spacediscr, space_size, dim=dim)\n",
    "\n",
    "evaluate_and_plot(methods, \n",
    "                  methods_data, \n",
    "                  method_categories, \n",
    "                  validation_initial_values_rough, \n",
    "                  validation_ref_sol_rough, \n",
    "                  space_grid, \n",
    "                  space_size, \n",
    "                  output_folder_dir, \n",
    "                  pde_name, \n",
    "                  dim=dim, \n",
    "                  nr_of_eval_runs=nr_of_eval_runs, \n",
    "                  plot_histogram=plot_histogram,\n",
    "                  legend_loc=None,\n",
    "                  nr_of_plots= 1 if test_run else 5\n",
    "                  )\n",
    "\n",
    "#Save all the data in an Excel sheet\n",
    "local_vars = locals()\n",
    "params_dict = {k: [v] for k, v in local_vars.items() if isinstance(v, (int, str, float)) and k[0] != '_'}\n",
    "save_excel_sheet(methods_data, params_dict, output_folder_dir + f'Results_{pde_name}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T06:24:33.839363Z",
     "start_time": "2024-05-21T06:24:32.106113Z"
    }
   },
   "outputs": [],
   "source": [
    "create_error_vs_comptime_plot(method_categories, output_folder_dir, pde_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_PDE_survey",
   "language": "python",
   "name": "venv_pde_survey"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
